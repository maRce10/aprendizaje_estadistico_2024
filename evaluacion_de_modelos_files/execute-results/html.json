{
  "hash": "c815146cdda94ef427aaf4f169e2107d",
  "result": {
    "engine": "knitr",
    "markdown": "---\ntitle: <font size=\"7\"><b>Entrenamiento y evaluación de modelos</b></font>\neditor_options: \n  chunk_output_type: console\n---\n\n::: {.cell}\n\n:::\n\n::: {.cell}\n\n:::\n\n\n::: {.alert .alert-info}\n# Objetivo del manual {.unnumbered .unlisted}\n\n- \n\n:::\n\nPaquetes a utilizar en este manual:\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# instalar/cargar paquetes\n\nsketchy::load_packages(\n  c(\"ggplot2\", \n    \"viridis\", \n    \"nnet\",\n    \"caret\",\n    \"glmnet\")\n  )\n```\n\n::: {.cell-output .cell-output-stderr}\n\n```\nLoading required package: nnet\n```\n\n\n:::\n:::\n\n\n# Entrenamiento de modelos de aprendizaje estadístico\n\nLa lógica detrás de cualquier método de entrenamiento de modelos estadísticos se centra en ajustar un modelo a un conjunto de datos con el fin de capturar la relación entre las variables predictoras y la variable de respuesta. El objetivo principal es aprender patrones subyacentes en los datos para hacer predicciones precisas o interpretar la relación entre las variables.\n\n\n## Pasos Fundamentales en el Entrenamiento de Modelos Estadísticos:\n\n\n```{mermaid}\n\nflowchart LR\n    A(Definir el Modelo) --> B(\"Especificar la\\nFunción de Pérdida\")\n    B --> C(\"Optimización\\ndel Modelo\")\n    C --> D(\"Regularización\")\n    D --> E(\"Evaluación\\ndel Modelo\")\n    E --> F(\"¿Es el rendimiento\\nsatisfactorio?\")\n    F -->|\"Sí\"| G(Modelo\\nFinal)\n    F -->|No| H(\"Realizar Ajustes\\ne Iteración\")\n    H --> A\n\n```\n\n\n\n\n- **Definir el Modelo**: Seleccionar el tipo de modelo estadístico (regresión lineal, regresión logística, árboles de decisión, etc.) que se ajusta a la naturaleza del problema y a la estructura de los datos. El modelo define la forma de la función que relaciona las variables predictoras X con la variable de respuesta Y.\n\n- **Especificar una Función de Pérdida (o Costo)**: La función de pérdida mide la diferencia entre las predicciones del modelo y los valores reales de la variable de respuesta. En los modelos de regresión, un ejemplo común es el error cuadrático medio (MSE), mientras que en clasificación, la entropía cruzada o el logaritmo de la verosimilitud son más adecuados.\n\n- **Optimización del Modelo**: El entrenamiento implica minimizar (o maximizar, dependiendo del enfoque) la función de pérdida ajustando los parámetros del modelo. Por ejemplo, en regresión lineal, se busca encontrar los coeficientes que minimicen la suma de los errores cuadráticos entre las predicciones y los valores observados. Métodos comunes para optimización incluyen el descenso de gradiente, la maximización de la verosimilitud y algoritmos especializados como el algoritmo EM.\n\n- **Regularización (en caso necesario)**: La regularización añade un término de penalización a la función de pérdida para evitar el sobreajuste. Ayuda a mantener el modelo más simple, controlando la magnitud de los coeficientes o reduciendo el número de variables seleccionadas.\n\n- **Evaluación del Modelo**: Una vez entrenado, el modelo se evalúa utilizando datos de prueba o técnicas de validación cruzada para estimar su rendimiento en datos no vistos. Las métricas de evaluación, como la precisión, el error absoluto medio o el índice F1, ayudan a determinar si el modelo generaliza bien.\n\n- **Ajustes e Iteración: Basado en la evaluación del modelo, puede ser necesario ajustar hiperparámetros, cambiar la arquitectura del modelo o realizar preprocesamiento adicional en los datos. Se itera sobre el proceso hasta que se logre un rendimiento satisfactorio.\n\n\n## Principios Clave:\n\n    Generalización: La capacidad del modelo para realizar predicciones precisas en nuevos datos.\n    Equilibrio entre sobreajuste y subajuste: El modelo debe ser lo suficientemente complejo para capturar patrones relevantes, pero no tan complejo que capture ruido específico del conjunto de entrenamiento.\n    Interpretabilidad vs. Complejidad: Modelos más complejos pueden proporcionar mejores predicciones, pero suelen ser más difíciles de interpretar.\n\nEn resumen, el entrenamiento de modelos estadísticos consiste en ajustar un modelo para que describa con precisión los datos observados y sea capaz de hacer predicciones precisas en nuevos datos, equilibrando la complejidad del modelo y su capacidad de generalización.\n\n# Validación Cruzada en Regresión Lineal\n\nLa validación cruzada se utiliza para evaluar el rendimiento de un modelo de regresión lineal, ayudando a identificar el nivel de ajuste adecuado y a prevenir el sobreajuste. Las técnicas de validación cruzada más comunes son:\n\nk-Fold Cross-Validation: Se divide el conjunto de datos en k subconjuntos (folds). En cada iteración, se entrena el modelo con k-1 subconjuntos y se prueba en el subconjunto restante. El proceso se repite k veces, promediando el error para obtener una estimación del error de generalización.\n\nLeave-One-Out Cross-Validation (LOOCV): Cada observación se usa como conjunto de prueba, y las restantes n-1 observaciones se utilizan para entrenar el modelo. Es útil en conjuntos de datos pequeños, pero puede ser costoso computacionalmente para grandes volúmenes de datos.\n\nEjemplo en R:\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Generar datos simulados\nset.seed(42)\nx <- rnorm(100)\ny <- 3 * x + rnorm(100, sd = 0.5)\n\n# Crear un marco de datos\ndatos <- data.frame(x = x, y = y)\n\n# Configuración de validación cruzada 10-fold\ncontrol <- trainControl(method = \"cv\", number = 10)\n\n# Entrenamiento del modelo con validación cruzada\nmodelo_cv <- train(y ~ x, data = datos, method = \"lm\", trControl = control)\nprint(modelo_cv)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nLinear Regression \n\n100 samples\n  1 predictor\n\nNo pre-processing\nResampling: Cross-Validated (10 fold) \nSummary of sample sizes: 89, 91, 91, 90, 90, 91, ... \nResampling results:\n\n  RMSE     Rsquared  MAE    \n  0.45531  0.98181   0.36177\n\nTuning parameter 'intercept' was held constant at a value of TRUE\n```\n\n\n:::\n:::\n\n\n# Técnicas de Remuestreo\n\nEl remuestreo permite evaluar la variabilidad del modelo al entrenarlo varias veces con diferentes subconjuntos del conjunto de datos original. Estas técnicas son útiles cuando el conjunto de datos es pequeño o cuando se desea evaluar la robustez del modelo.\n\nBootstrap: Es una técnica de remuestreo con reemplazo. Se crean múltiples subconjuntos de datos a partir del original y se entrena el modelo en cada uno de ellos. Permite estimar la incertidumbre de los coeficientes del modelo.\n\nEjemplo en R con Bootstrap:\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Configuración para el bootstrap\ncontrol_boot <- trainControl(method = \"boot\", number = 100)\n\n# Entrenamiento del modelo con bootstrap\nmodelo_boot <- train(y ~ x, data = datos, method = \"lm\", trControl = control_boot)\nprint(modelo_boot)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nLinear Regression \n\n100 samples\n  1 predictor\n\nNo pre-processing\nResampling: Bootstrapped (100 reps) \nSummary of sample sizes: 100, 100, 100, 100, 100, 100, ... \nResampling results:\n\n  RMSE     Rsquared  MAE    \n  0.46044  0.98041   0.36018\n\nTuning parameter 'intercept' was held constant at a value of TRUE\n```\n\n\n:::\n:::\n\n\n# Uso de Validación Cruzada para Evaluar Modelos\n\nEn regresión lineal, se utilizan medidas de error como el error cuadrático medio (MSE) o el error absoluto medio (MAE) para evaluar el rendimiento del modelo durante la validación cruzada. La validación cruzada permite identificar si el modelo es demasiado complejo (sobreajuste) o demasiado simple (subajuste).\nEjemplo en R calculando el MSE:\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Calcular el MSE en el conjunto de prueba\npredicciones <- predict(modelo_cv, datos)\nmse <- mean((datos$y - predicciones)^2)\ncat(\"Error cuadrático medio (MSE):\", mse, \"\\n\")\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nError cuadrático medio (MSE): 0.20214 \n```\n\n\n:::\n:::\n\n\n\n# Validación Cruzada y Técnicas de Remuestreo\n\nValidación cruzada es una técnica que permite evaluar el rendimiento de un modelo al dividir los datos en varios subconjuntos (folds), entrenando el modelo en algunos y evaluándolo en otros:\n\n- **k-Fold Cross-Validation**: Los datos se dividen en k subconjuntos, y el modelo se entrena k veces, usando k-1 conjuntos para el entrenamiento y uno para la prueba en cada iteración.\n- **Leave-One-Out Cross-Validation (LOOCV)**: Cada instancia de los datos se usa como conjunto de prueba, mientras que el resto se usa para el entrenamiento.\n- **Bootstrap**: Involucra el remuestreo de los datos con reemplazo para crear múltiples subconjuntos de entrenamiento.\n\nEjemplo en R:\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Cargar librería caret para validación cruzada\nlibrary(caret)\n\n# Generar datos simulados\nset.seed(123)\nx <- matrix(rnorm(100 * 20), 100, 20)\ny <- factor(sample(c(\"A\", \"B\"), 100, replace = TRUE))\n\ndatos_log <- data.frame(x, y)\n\n# Configuración de validación cruzada 10-fold\ncontrol <- trainControl(method = \"cv\", number = 10)\n\n# Entrenamiento del modelo con validación cruzada\nmodelo_cv <- train(y ~ ., data = datos_log, method = \"glm\", family = binomial, trControl = control)\nprint(modelo_cv)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nGeneralized Linear Model \n\n100 samples\n 20 predictor\n  2 classes: 'A', 'B' \n\nNo pre-processing\nResampling: Cross-Validated (10 fold) \nSummary of sample sizes: 90, 89, 90, 91, 89, 91, ... \nResampling results:\n\n  Accuracy  Kappa    \n  0.49788   -0.023208\n```\n\n\n:::\n\n```{.r .cell-code}\nsummary(modelo_cv)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\nCall:\nNULL\n\nCoefficients:\n            Estimate Std. Error z value Pr(>|z|)  \n(Intercept)  -0.3659     0.2583   -1.42    0.157  \nX1            0.0870     0.2775    0.31    0.754  \nX2            0.0593     0.2685    0.22    0.825  \nX3            0.4065     0.2678    1.52    0.129  \nX4            0.2473     0.2622    0.94    0.346  \nX5            0.5893     0.2800    2.10    0.035 *\nX6           -0.0255     0.2823   -0.09    0.928  \nX7           -0.0750     0.2479   -0.30    0.762  \nX8            0.3205     0.2569    1.25    0.212  \nX9            0.6021     0.2553    2.36    0.018 *\nX10          -0.0139     0.2571   -0.05    0.957  \nX11          -0.5509     0.2862   -1.92    0.054 .\nX12          -0.2202     0.2696   -0.82    0.414  \nX13          -0.1534     0.2836   -0.54    0.589  \nX14           0.4374     0.2896    1.51    0.131  \nX15           0.5737     0.2736    2.10    0.036 *\nX16          -0.5108     0.3243   -1.58    0.115  \nX17           0.3061     0.2612    1.17    0.241  \nX18          -0.3773     0.2526   -1.49    0.135  \nX19          -0.3331     0.2487   -1.34    0.180  \nX20           0.1238     0.2383    0.52    0.603  \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n(Dispersion parameter for binomial family taken to be 1)\n\n    Null deviance: 137.63  on 99  degrees of freedom\nResidual deviance: 111.93  on 79  degrees of freedom\nAIC: 153.9\n\nNumber of Fisher Scoring iterations: 4\n```\n\n\n:::\n:::\n\n\n# Uso de Validación Cruzada para Evaluar Modelos\n\nLa validación cruzada es utilizada para obtener una estimación del error del modelo. A través de la técnica de validación cruzada se busca identificar la configuración de hiperparámetros que minimiza el error en el conjunto de prueba.\nEjemplo en R:\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Configuración para validación cruzada con ajuste de hiperparámetros\ncontrol_tune <- trainControl(method = \"repeatedcv\", number = 10, repeats = 3)\n\n# Entrenamiento con diferentes hiperparámetros para el modelo de regresión logística\ngrid <- expand.grid(lambda = seq(0, 1, by = 0.1), alpha = seq(0, 1, by = 0.1))\nmodelo_tune <- train(y ~ ., data = datos_log, method = \"glmnet\", trControl = control_tune, tuneGrid = grid)\nprint(modelo_tune)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nglmnet \n\n100 samples\n 20 predictor\n  2 classes: 'A', 'B' \n\nNo pre-processing\nResampling: Cross-Validated (10 fold, repeated 3 times) \nSummary of sample sizes: 90, 90, 90, 91, 89, 90, ... \nResampling results across tuning parameters:\n\n  alpha  lambda  Accuracy  Kappa     \n  0.0    0.0     0.52886    0.0343446\n  0.0    0.1     0.52620    0.0176571\n  0.0    0.2     0.54997    0.0550225\n  0.0    0.3     0.53293    0.0159150\n  0.0    0.4     0.53620    0.0155997\n  0.0    0.5     0.55929    0.0594068\n  0.0    0.6     0.56263    0.0624496\n  0.0    0.7     0.56232    0.0580332\n  0.0    0.8     0.55559    0.0392748\n  0.0    0.9     0.55559    0.0362088\n  0.0    1.0     0.55862    0.0395610\n  0.1    0.0     0.52552    0.0320867\n  0.1    0.1     0.54293    0.0467734\n  0.1    0.2     0.56899    0.0876765\n  0.1    0.3     0.55923    0.0517916\n  0.1    0.4     0.57838    0.0769984\n  0.1    0.5     0.57468    0.0656129\n  0.1    0.6     0.55061    0.0026598\n  0.1    0.7     0.55024    0.0000000\n  0.1    0.8     0.55024    0.0000000\n  0.1    0.9     0.55024    0.0000000\n  0.1    1.0     0.55024    0.0000000\n  0.2    0.0     0.52552    0.0320867\n  0.2    0.1     0.53855    0.0366067\n  0.2    0.2     0.57808    0.0901100\n  0.2    0.3     0.56801    0.0495956\n  0.2    0.4     0.55024    0.0000000\n  0.2    0.5     0.55024    0.0000000\n  0.2    0.6     0.55024    0.0000000\n  0.2    0.7     0.55024    0.0000000\n  0.2    0.8     0.55024    0.0000000\n  0.2    0.9     0.55024    0.0000000\n  0.2    1.0     0.55024    0.0000000\n  0.3    0.0     0.52552    0.0320867\n  0.3    0.1     0.56172    0.0751321\n  0.3    0.2     0.56936    0.0584093\n  0.3    0.3     0.55024    0.0000000\n  0.3    0.4     0.55024    0.0000000\n  0.3    0.5     0.55024    0.0000000\n  0.3    0.6     0.55024    0.0000000\n  0.3    0.7     0.55024    0.0000000\n  0.3    0.8     0.55024    0.0000000\n  0.3    0.9     0.55024    0.0000000\n  0.3    1.0     0.55024    0.0000000\n  0.4    0.0     0.52923    0.0393742\n  0.4    0.1     0.55522    0.0571448\n  0.4    0.2     0.54758   -0.0032926\n  0.4    0.3     0.55024    0.0000000\n  0.4    0.4     0.55024    0.0000000\n  0.4    0.5     0.55024    0.0000000\n  0.4    0.6     0.55024    0.0000000\n  0.4    0.7     0.55024    0.0000000\n  0.4    0.8     0.55024    0.0000000\n  0.4    0.9     0.55024    0.0000000\n  0.4    1.0     0.55024    0.0000000\n  0.5    0.0     0.52923    0.0393742\n  0.5    0.1     0.57209    0.0787931\n  0.5    0.2     0.55024    0.0000000\n  0.5    0.3     0.55024    0.0000000\n  0.5    0.4     0.55024    0.0000000\n  0.5    0.5     0.55024    0.0000000\n  0.5    0.6     0.55024    0.0000000\n  0.5    0.7     0.55024    0.0000000\n  0.5    0.8     0.55024    0.0000000\n  0.5    0.9     0.55024    0.0000000\n  0.5    1.0     0.55024    0.0000000\n  0.6    0.0     0.52923    0.0393742\n  0.6    0.1     0.56542    0.0563986\n  0.6    0.2     0.55024    0.0000000\n  0.6    0.3     0.55024    0.0000000\n  0.6    0.4     0.55024    0.0000000\n  0.6    0.5     0.55024    0.0000000\n  0.6    0.6     0.55024    0.0000000\n  0.6    0.7     0.55024    0.0000000\n  0.6    0.8     0.55024    0.0000000\n  0.6    0.9     0.55024    0.0000000\n  0.6    1.0     0.55024    0.0000000\n  0.7    0.0     0.52923    0.0393742\n  0.7    0.1     0.55626    0.0262045\n  0.7    0.2     0.55024    0.0000000\n  0.7    0.3     0.55024    0.0000000\n  0.7    0.4     0.55024    0.0000000\n  0.7    0.5     0.55024    0.0000000\n  0.7    0.6     0.55024    0.0000000\n  0.7    0.7     0.55024    0.0000000\n  0.7    0.8     0.55024    0.0000000\n  0.7    0.9     0.55024    0.0000000\n  0.7    1.0     0.55024    0.0000000\n  0.8    0.0     0.52923    0.0393742\n  0.8    0.1     0.54158   -0.0127255\n  0.8    0.2     0.55024    0.0000000\n  0.8    0.3     0.55024    0.0000000\n  0.8    0.4     0.55024    0.0000000\n  0.8    0.5     0.55024    0.0000000\n  0.8    0.6     0.55024    0.0000000\n  0.8    0.7     0.55024    0.0000000\n  0.8    0.8     0.55024    0.0000000\n  0.8    0.9     0.55024    0.0000000\n  0.8    1.0     0.55024    0.0000000\n  0.9    0.0     0.52923    0.0393742\n  0.9    0.1     0.54084   -0.0180451\n  0.9    0.2     0.55024    0.0000000\n  0.9    0.3     0.55024    0.0000000\n  0.9    0.4     0.55024    0.0000000\n  0.9    0.5     0.55024    0.0000000\n  0.9    0.6     0.55024    0.0000000\n  0.9    0.7     0.55024    0.0000000\n  0.9    0.8     0.55024    0.0000000\n  0.9    0.9     0.55024    0.0000000\n  0.9    1.0     0.55024    0.0000000\n  1.0    0.0     0.52923    0.0393742\n  1.0    0.1     0.54721   -0.0059524\n  1.0    0.2     0.55024    0.0000000\n  1.0    0.3     0.55024    0.0000000\n  1.0    0.4     0.55024    0.0000000\n  1.0    0.5     0.55024    0.0000000\n  1.0    0.6     0.55024    0.0000000\n  1.0    0.7     0.55024    0.0000000\n  1.0    0.8     0.55024    0.0000000\n  1.0    0.9     0.55024    0.0000000\n  1.0    1.0     0.55024    0.0000000\n\nAccuracy was used to select the optimal model using the largest value.\nThe final values used for the model were alpha = 0.1 and lambda = 0.4.\n```\n\n\n:::\n:::\n\n\n# Medidas de Evaluación\n\nLas siguientes son medidas comunes para evaluar el rendimiento de un modelo:\n\nMatriz de Confusión: Resume el rendimiento del modelo en términos de verdaderos positivos, falsos positivos, verdaderos negativos y falsos negativos.\n\nPrecisión: Proporción de predicciones correctas sobre el total de predicciones.\nPrecisión=TPTP+FP\nPrecisión=TP+FPTP​\n\n$$\n\\text{Odds} = \\frac{\\text{Probabilidad de éxito}}{\\text{Probabilidad de fracaso}} = \\frac{P(E)}{1 - P(E)}\n$$\n\n\nRecall (Sensibilidad): Proporción de verdaderos positivos sobre el total de casos positivos.\nRecall=TPTP+FN\nRecall=TP+FNTP​\n\nÍndice F1: Es la media armónica de la precisión y el recall.\nF1=2×Precisioˊn×RecallPrecisioˊn+Recall\nF1=2×Precisioˊn+RecallPrecisioˊn×Recall​\n\nEjemplo en R:\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Crear una matriz de confusión\npred <- predict(modelo_cv, datos_log)\nconfusion <- confusionMatrix(pred, datos_log$y)\nprint(confusion)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nConfusion Matrix and Statistics\n\n          Reference\nPrediction  A  B\n         A 44 17\n         B 11 28\n                                        \n               Accuracy : 0.72          \n                 95% CI : (0.621, 0.805)\n    No Information Rate : 0.55          \n    P-Value [Acc > NIR] : 0.00036       \n                                        \n                  Kappa : 0.427         \n                                        \n Mcnemar's Test P-Value : 0.34470       \n                                        \n            Sensitivity : 0.800         \n            Specificity : 0.622         \n         Pos Pred Value : 0.721         \n         Neg Pred Value : 0.718         \n             Prevalence : 0.550         \n         Detection Rate : 0.440         \n   Detection Prevalence : 0.610         \n      Balanced Accuracy : 0.711         \n                                        \n       'Positive' Class : A             \n                                        \n```\n\n\n:::\n\n```{.r .cell-code}\n# Obtener precisión, recall e índice F1\nprecision <- confusion$byClass[\"Pos Pred Value\"]\nrecall <- confusion$byClass[\"Sensitivity\"]\nf1_score <- 2 * ((precision * recall) / (precision + recall))\n\ncat(\"Precisión:\", precision, \"\\n\")\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nPrecisión: 0.72131 \n```\n\n\n:::\n\n```{.r .cell-code}\ncat(\"Recall:\", recall, \"\\n\")\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nRecall: 0.8 \n```\n\n\n:::\n\n```{.r .cell-code}\ncat(\"Índice F1:\", f1_score, \"\\n\")\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nÍndice F1: 0.75862 \n```\n\n\n:::\n:::\n\n\n4. Validación Cruzada y División de Conjuntos de Datos\n\nPara evaluar correctamente un modelo, se suele dividir el conjunto de datos en:\n\nConjunto de entrenamiento: Usado para entrenar el modelo.\nConjunto de validación: Utilizado para la selección de hiperparámetros.\nConjunto de prueba: Usado para evaluar el rendimiento final.\n\nEjemplo en R:\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# División de los datos en conjunto de entrenamiento y prueba\nset.seed(123)\ntrainIndex <- createDataPartition(datos_log$y, p = 0.8)[[1]]\nx_train <- datos_log[trainIndex, ]\ny_train <- datos_log$y[trainIndex]\nx_test <- datos_log[-trainIndex, ]\ny_test <- datos_log$y[-trainIndex]\n\n# Entrenar un modelo en los datos de entrenamiento\nmodelo_final <- train(x_train, y_train, method = \"glm\", family = binomial)\n\n# Evaluar en el conjunto de prueba\npred_test <- predict(modelo_final, x_test)\nconfusion_test <- confusionMatrix(pred_test, y_test)\nprint(confusion_test)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nConfusion Matrix and Statistics\n\n          Reference\nPrediction  A  B\n         A 11  0\n         B  0  9\n                                    \n               Accuracy : 1         \n                 95% CI : (0.832, 1)\n    No Information Rate : 0.55      \n    P-Value [Acc > NIR] : 6.42e-06  \n                                    \n                  Kappa : 1         \n                                    \n Mcnemar's Test P-Value : NA        \n                                    \n            Sensitivity : 1.00      \n            Specificity : 1.00      \n         Pos Pred Value : 1.00      \n         Neg Pred Value : 1.00      \n             Prevalence : 0.55      \n         Detection Rate : 0.55      \n   Detection Prevalence : 0.55      \n      Balanced Accuracy : 1.00      \n                                    \n       'Positive' Class : A         \n                                    \n```\n\n\n:::\n:::\n\n\n\nEsta clase abarca los conceptos de validación cruzada y técnicas de remuestreo, el uso de la validación cruzada para evaluar modelos, las medidas de evaluación (matriz de confusión, precisión, recall, índice F1) y la división de conjuntos de datos. Los ejemplos en R proporcionan un enfoque práctico para cada concepto, ayudando a comprender la importancia de una evaluación adecuada en el aprendizaje estadístico.\n\n::: {.alert .alert-info}\n## Ejercicio 1\n\n\n:::\n\n---\n\n# Información de la sesión {.unnumbered .unlisted}\n\n\n::: {.cell}\n::: {.cell-output .cell-output-stdout}\n\n```\nR version 4.4.1 (2024-06-14)\nPlatform: x86_64-pc-linux-gnu\nRunning under: Ubuntu 22.04.4 LTS\n\nMatrix products: default\nBLAS:   /usr/lib/x86_64-linux-gnu/blas/libblas.so.3.10.0 \nLAPACK: /usr/lib/x86_64-linux-gnu/lapack/liblapack.so.3.10.0\n\nlocale:\n [1] LC_CTYPE=en_US.UTF-8       LC_NUMERIC=C              \n [3] LC_TIME=es_CR.UTF-8        LC_COLLATE=en_US.UTF-8    \n [5] LC_MONETARY=es_CR.UTF-8    LC_MESSAGES=en_US.UTF-8   \n [7] LC_PAPER=es_CR.UTF-8       LC_NAME=C                 \n [9] LC_ADDRESS=C               LC_TELEPHONE=C            \n[11] LC_MEASUREMENT=es_CR.UTF-8 LC_IDENTIFICATION=C       \n\ntime zone: America/Costa_Rica\ntzcode source: system (glibc)\n\nattached base packages:\n[1] stats     graphics  grDevices utils     datasets  methods   base     \n\nother attached packages:\n[1] nnet_7.3-19       caret_6.0-94      lattice_0.22-6    glmnet_4.1-8     \n[5] Matrix_1.7-0      viridis_0.6.5     viridisLite_0.4.2 ggplot2_3.5.1    \n[9] knitr_1.48       \n\nloaded via a namespace (and not attached):\n [1] gtable_0.3.5         shape_1.4.6.1        xfun_0.48           \n [4] remotes_2.5.0        htmlwidgets_1.6.4    recipes_1.0.10      \n [7] vctrs_0.6.5          tools_4.4.1          generics_0.1.3      \n[10] stats4_4.4.1         parallel_4.4.1       proxy_0.4-27        \n[13] tibble_3.2.1         fansi_1.0.6          ModelMetrics_1.2.2.2\n[16] pkgconfig_2.0.3      data.table_1.15.4    lifecycle_1.0.4     \n[19] stringr_1.5.1        compiler_4.4.1       munsell_0.5.1       \n[22] codetools_0.2-20     sketchy_1.0.3        htmltools_0.5.8.1   \n[25] class_7.3-22         yaml_2.3.10          prodlim_2024.06.25  \n[28] crayon_1.5.3         pillar_1.9.0         MASS_7.3-61         \n[31] gower_1.0.1          iterators_1.0.14     rpart_4.1.23        \n[34] foreach_1.5.2        nlme_3.1-165         parallelly_1.38.0   \n[37] lava_1.8.0           packrat_0.9.2        tidyselect_1.2.1    \n[40] digest_0.6.37        stringi_1.8.4        future_1.34.0       \n[43] dplyr_1.1.4          reshape2_1.4.4       purrr_1.0.2         \n[46] listenv_0.9.1        splines_4.4.1        fastmap_1.2.0       \n[49] grid_4.4.1           colorspace_2.1-1     cli_3.6.3           \n[52] magrittr_2.0.3       survival_3.7-0       utf8_1.2.4          \n[55] e1071_1.7-16         future.apply_1.11.2  withr_3.0.1         \n[58] scales_1.3.0         lubridate_1.9.3      timechange_0.3.0    \n[61] rmarkdown_2.28       globals_0.16.3       timeDate_4032.109   \n[64] gridExtra_2.3        evaluate_1.0.0       hardhat_1.4.0       \n[67] rlang_1.1.4          Rcpp_1.0.13          xaringanExtra_0.8.0 \n[70] glue_1.8.0           pROC_1.18.5          ipred_0.9-14        \n[73] rstudioapi_0.16.0    jsonlite_1.8.9       R6_2.5.1            \n[76] plyr_1.8.9          \n```\n\n\n:::\n:::\n",
    "supporting": [],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}